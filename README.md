# ğŸ“š Book & Quote Scraper - Scrapy Training Project

Un projet de formation full-stack dÃ©montrant l'utilisation de **Scrapy** pour scraper des donnÃ©es, les enrichir avec des **embeddings vectoriels** (Azure OpenAI), et les stocker dans **Azure PostgreSQL** avec **pgvector** pour alimenter un moteur de recommandation sÃ©mantique.

## ğŸ¯ Objectif

Ce projet fait partie d'un Ã©cosystÃ¨me de formation comprenant :
- **Ce scraper** : Collecte automatisÃ©e de donnÃ©es (livres + citations) avec enrichissement vectoriel
- **API REST** : Expose les donnÃ©es et un moteur de recommandation intelligent
  - ğŸ”— [API Documentation](https://cpetit-bookscraperapi.kindglacier-2234e5a4.francecentral.azurecontainerapps.io/docs)
- **Infrastructure Azure** : DÃ©ploiement containerisÃ© avec exÃ©cution pÃ©riodique (cron jobs)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scrapy Spiders     â”‚
â”‚  â”œâ”€ Books Spider    â”‚  â”€â”€â†’  books.toscrape.com
â”‚  â””â”€ Quotes Spider   â”‚  â”€â”€â†’  quotes.toscrape.com/js
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure OpenAI API    â”‚  â”€â”€â†’  Embeddings (text-embedding-3-small)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure PostgreSQL    â”‚
â”‚ + pgvector          â”‚  â”€â”€â†’  Recherche vectorielle
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend    â”‚  â”€â”€â†’  API + Moteur de recommandation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ FonctionnalitÃ©s

### ğŸ•·ï¸ Spiders

#### 1. **Books Spider** (`books`)
- **Source** : https://books.toscrape.com/
- **Technologie** : CrawlSpider avec rÃ¨gles de navigation
- **DonnÃ©es collectÃ©es** :
  - MÃ©tadonnÃ©es : titre, prix, rating, stock, UPC, genre
  - Description enrichie avec embeddings vectoriels (1536 dimensions)
  - Historique des variations (prix, stock, reviews) avec randomisation
- **Stockage** : 3 tables PostgreSQL (`books`, `genres`, `updates`)

#### 2. **Quotes Spider** (`quotes`)
- **Source** : https://quotes.toscrape.com/js
- **Technologie** : Parsing JavaScript avec `chompjs`
- **DonnÃ©es collectÃ©es** :
  - Citations avec tags
  - Auteurs avec liens Goodreads
- **Stockage** : 2 tables PostgreSQL (`quotes`, `authors`)

### ğŸ§  Intelligence Artificielle

- **Embeddings vectoriels** gÃ©nÃ©rÃ©s via Azure OpenAI (modÃ¨le `text-embedding-3-small`)
- **Index IVFFLAT** pour recherche sÃ©mantique ultra-rapide
- UtilisÃ©s par le moteur de recommandation de l'API

### ğŸ“Š Randomisation des donnÃ©es

Les donnÃ©es de `books.toscrape.com` Ã©tant statiques, le scraper ajoute des variations alÃ©atoires :
- Prix : Â±5â‚¬
- Stock : +0 Ã  +5 unitÃ©s
- Reviews : +0 Ã  +5 avis
- Rating : Â±1 Ã©toile (limitÃ© entre 0 et 5)

Cela permet de simuler l'Ã©volution temporelle des donnÃ©es pour l'endpoint de monitoring de l'API.

## ğŸš€ Installation & Usage

### PrÃ©requis

- Python 3.11+
- Azure PostgreSQL avec extension `pgvector`
- Azure OpenAI API (dÃ©ploiement embeddings)

### 1ï¸âƒ£ Installation locale

```bash
# Cloner le repository
git clone https://github.com/CpHeat/data-scraper.git
cd Scraping

# CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configuration

CrÃ©er un fichier `data_scraper/.env` avec vos credentials Azure :

```env
# Azure PostgreSQL
AZURE_PG_HOST=your-server.postgres.database.azure.com
AZURE_PG_PORT=5432
AZURE_PG_DB=your-database
AZURE_PG_USER=your-username
AZURE_PG_PASSWORD=your-password
AZURE_PG_SSL_MODE=require

# Azure OpenAI
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
```

### 3ï¸âƒ£ ExÃ©cution locale

```bash
cd data_scraper

# Lister les spiders disponibles
scrapy list

# ExÃ©cuter un spider spÃ©cifique
scrapy crawl books
scrapy crawl quotes

# ExÃ©cuter avec logs dÃ©taillÃ©s
scrapy crawl books -L DEBUG
```

## ğŸ³ Docker

### Build et exÃ©cution locale

```bash
# Build de l'image
docker build -t data-scraper .

# ExÃ©cution avec docker-compose
docker-compose up --build

# ExÃ©cution manuelle
docker run --env-file data_scraper/.env data-scraper
```

## ğŸ—„ï¸ SchÃ©ma de base de donnÃ©es

### Tables crÃ©Ã©es automatiquement

#### **Books**
```sql
CREATE TABLE books (
    id SERIAL PRIMARY KEY,
    type VARCHAR(500),
    title VARCHAR(500),
    thumbnail VARCHAR(500),
    link VARCHAR(500),
    description TEXT,
    genre VARCHAR(100),
    upc VARCHAR(100) UNIQUE,
    availability BOOLEAN,
    description_embedding vector(1536)  -- Embeddings OpenAI
);

-- Index vectoriel pour recherche sÃ©mantique
CREATE INDEX books_description_embedding_idx
ON books USING ivfflat (description_embedding vector_cosine_ops);
```

#### **Updates** (Historique temporel)
```sql
CREATE TABLE updates (
    id SERIAL PRIMARY KEY,
    book_id INTEGER,
    tax INTEGER,
    rating INTEGER,
    price INTEGER,
    stock INTEGER,
    reviews INTEGER,
    scraped_at TIMESTAMPTZ
);
```

#### **Quotes**
```sql
CREATE TABLE quotes (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    author VARCHAR(200) NOT NULL,
    tags VARCHAR(500),
    scraped_at TIMESTAMPTZ,
    UNIQUE (content, author)
);
```

#### **Authors**
```sql
CREATE TABLE authors (
    id SERIAL PRIMARY KEY,
    slug VARCHAR(100) UNIQUE,
    name VARCHAR(200),
    link VARCHAR(200)
);
```

## ğŸ“¦ DÃ©pendances principales

```
scrapy          # Framework de scraping
psycopg2        # Driver PostgreSQL
pgvector        # Extension vectorielle
openai          # Client Azure OpenAI
chompjs         # Parser JavaScript
python-dotenv   # Gestion variables d'environnement
```

## ğŸ”§ Configuration Scrapy

Le scraper est configurÃ© pour un scraping efficace :

```python
ROBOTSTXT_OBEY = True
CONCURRENT_REQUESTS = 32
CONCURRENT_REQUESTS_PER_DOMAIN = 32
DOWNLOAD_DELAY = 0.1
HTTPCACHE_ENABLED = True
HTTPCACHE_EXPIRATION_SECS = 60*60*24  # 24h
```

## ğŸ“ Points d'apprentissage

Ce projet illustre :

1. **Scrapy avancÃ©**
   - CrawlSpider avec rÃ¨gles de navigation
   - ItemLoaders pour normalisation
   - Pipelines personnalisÃ©s
   - Gestion du cache HTTP

2. **Parsing complexe**
   - Extraction CSS/XPath
   - Parsing de donnÃ©es JavaScript avec `chompjs`

3. **IA & Embeddings**
   - GÃ©nÃ©ration d'embeddings avec Azure OpenAI
   - Optimisation (gÃ©nÃ©ration uniquement si description modifiÃ©e)

4. **Base de donnÃ©es vectorielle**
   - Extension pgvector
   - Index IVFFLAT pour recherche cosine
   - Gestion des upserts et duplicatas

5. **DevOps & Cloud**
   - Dockerisation
   - Azure Container Apps (Jobs)
   - Cron scheduling
   - Configuration via variables d'environnement

6. **Architecture Microservices**
   - SÃ©paration scraper/API
   - Communication via base de donnÃ©es partagÃ©e

## ğŸ”— Ressources

- **API du projet** : [https://cpetit-bookscraperapi.kindglacier-2234e5a4.francecentral.azurecontainerapps.io/docs](https://cpetit-bookscraperapi.kindglacier-2234e5a4.francecentral.azurecontainerapps.io/docs)
- **Source des donnÃ©es** :
  - [books.toscrape.com](https://books.toscrape.com)
  - [quotes.toscrape.com](https://quotes.toscrape.com)
- **Documentation Scrapy** : [docs.scrapy.org](https://docs.scrapy.org)
- **pgvector** : [github.com/pgvector/pgvector](https://github.com/pgvector/pgvector)

## ğŸ“ Licence

MIT License - Voir le fichier [LICENSE](LICENSE)

## ğŸ‘¤ Auteur

**Charles Petit**
Projet de formation - Portfolio dÃ©veloppeur IA